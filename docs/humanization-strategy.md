# HumanTouch 人性化策略技术文档

> 深入解析 AI 检测原理与 HumanTouch 的科学应对策略

## 目录

- [AI 检测器工作原理](#ai-检测器工作原理)
- [核心检测指标详解](#核心检测指标详解)
- [研究发现与数据支撑](#研究发现与数据支撑)
- [HumanTouch 6轮处理策略](#humantouch-6轮处理策略)
- [自适应策略系统](#自适应策略系统)
- [风格差异化处理](#风格差异化处理)
- [技术实现细节](#技术实现细节)
- [参考文献](#参考文献)

---

## AI 检测器工作原理

### 主流检测器

HumanTouch 针对三大主流 AI 检测器进行优化：

| 检测器 | 公司 | 检测方法 | 特点 |
|--------|------|----------|------|
| **ZeroGPT** | ZeroGPT Inc. | DeepAnalyse™ 系统 | 基于深度学习的多维分析 |
| **GPTZero** | GPTZero Inc. | 困惑度 + 突发性分析 | 学术界广泛使用 |
| **Copyleaks** | Copyleaks Ltd. | AI 分类器 + 句子级分析 | 企业级解决方案 |

### 检测原理

AI 检测器主要通过以下方式判断文本：

1. **统计特征分析**：分析词频、句长分布、词汇多样性等
2. **语言模型对比**：使用 AI 模型预测文本，对比预测结果
3. **模式识别**：识别 AI 写作的典型模式和模板

---

## 核心检测指标详解

### 1. 困惑度 (Perplexity)

**定义**：语言模型对文本的"惊讶程度"。困惑度越低，表示文本越可预测，越像 AI 生成。

**计算原理**：
```
Perplexity = exp(-1/N × Σ log P(word_i | context))
```

**AI vs 人类对比**：

| 特征 | AI 文本 | 人类文本 |
|------|---------|----------|
| 困惑度值 | 低 (10-30) | 高 (50-150) |
| 词汇选择 | 高频、常见词 | 多样、有时意外 |
| 搭配方式 | 固定搭配 | 创意搭配 |

**提高困惑度的方法**：
- 使用同义词替换（但避免生僻词）
- 打破固定搭配
- 引入具象化表达和比喻

### 2. 突发性 (Burstiness)

**定义**：句子复杂度和长度的变化程度。人类写作呈现"突发性"——句子长度剧烈变化。

**AI vs 人类对比**：

```
AI 文本句长分布：
████████████ 15词
████████████ 16词
████████████ 14词
████████████ 15词
（均匀分布）

人类文本句长分布：
██ 3词
████████████████████ 25词
████ 5词
██████████████████████████████ 40词
█ 2词
（高突发性）
```

**增加突发性的方法**：
- 在长句后插入短句（"就这样。"/"没错。"）
- 拆分长句为多个短句
- 偶尔使用特别长的复合句
- 使用反问句、感叹句

### 3. 词汇多样性 (Type-Token Ratio)

**定义**：不同词汇数量与总词汇数量的比值。

```
TTR = 不同词汇数 / 总词汇数
```

**AI 典型问题**：
- 重复使用相同的过渡词（"首先"、"此外"）
- 固定的句式模板
- 有限的形容词库

### 4. 句法结构 (Syntactic Patterns)

**AI 典型句法模式**：
- 主谓宾结构规整
- 并列结构对称
- 逻辑连接词密集

**人类句法特征**：
- 句式多变（倒装、省略、插入语）
- 口语化表达
- 思维跳跃

---

## 研究发现与数据支撑

### 学术研究结果

| 研究 | 发现 | 来源 |
|------|------|------|
| Mitchell et al. (2023) | 改写可将检测率从 70.3% 降至 4.6% | ResearchGate |
| Pangram Labs | 单纯提示"增加困惑度"效果差 (98% 仍被检测) | 行业报告 |
| 独立评测 | 检测器准确率约 70%，假阳性率 10-28% | 多方验证 |

### 各检测器特点

**ZeroGPT**：
- 使用专有 DeepAnalyse™ 系统
- 对词汇多样性敏感
- 中文支持较好

**GPTZero**：
- 公开困惑度和突发性分析
- 学术论文检测常用
- 对句法结构敏感

**Copyleaks**：
- 句子级别分析
- 企业级产品
- 对整体模式敏感

---

## HumanTouch 6轮处理策略

### 策略设计原理

每一轮针对特定的 AI 特征，而非泛泛的"人性化"：

### 第1轮：AI 模式消除

**目标**：移除 AI 写作的典型模式和惯用语

**消除的 AI 特征**：

| 类型 | AI 惯用语（中文） | AI 惯用语（英文） |
|------|------------------|------------------|
| 列表连接 | 首先、其次、再次、最后 | firstly, secondly, finally |
| 总结语 | 综上所述、总而言之 | in conclusion, to summarize |
| 强调语 | 需要注意的是、值得一提的是 | it is important to note |
| 正式动词 | 进行、实现、开展、推动 | utilize, implement, facilitate |
| 模板句式 | 在...方面、从...角度 | in terms of, with regard to |

**改写策略**：
```
❌ "首先，我们需要进行数据分析。其次，我们将实现模型优化。"
✅ "数据分析是第一步。模型优化？那是接下来要处理的。"
```

### 第2轮：句法重组

**目标**：制造人类写作特有的"突发性"

**技术手段**：

1. **句长变异**
   ```
   原文：这个问题非常重要，因为它影响了整个系统的性能。
   改写：这问题挺重要。为什么？它直接影响系统性能。
   ```

2. **句式变换**
   ```
   原文：研究人员发现了这个现象。
   改写：这个现象，研究人员还真给发现了。
   ```

3. **段落节奏**
   - 有的段落只有一两句
   - 有的段落信息密集
   - 避免每段 3-4 句的标准结构

### 第3轮：词汇多样化

**目标**：提高文本困惑度

**策略**：

| 原表达 | 替换方案 |
|--------|---------|
| 非常重要 | 挺关键的、不能忽视、这点很要紧 |
| 取得成功 | 事儿成了、搞定了、做成了 |
| 具有重要意义 | 意义不小、挺有分量 |
| 发展很快 | 像坐火箭一样、突飞猛进 |

**注意**：
- 不要简单替换为生僻词
- 选择同样自然但更少用的表达
- 引入具象化比喻

### 第4轮：思维痕迹注入

**目标**：模拟人类思维过程的痕迹

**注入元素**：

1. **思维跳跃**
   - "说到这儿，我想起..."
   - "等等，这里要补充一下"

2. **不确定表达**
   - "大概是..."
   - "我记得好像..."
   - "这点我不太确定，但..."

3. **个人立场**
   - "我个人觉得..."
   - "不得不说，..."
   - "老实说，..."

4. **情感反应**
   - "有意思的是..."
   - "让人惊讶的是..."

### 第5轮：深度打磨

**目标**：最终质量保证

**打磨要点**：
- 朗读测试：读出来是否像人说的话？
- 独特性注入：添加 1-2 处独特比喻
- 不完美性：人类写作不会完美
- 节奏调整：开头吸引人，结尾自然

### 第6轮：极限处理

**目标**：处理顽固的 AI 痕迹

**极限策略**：
- 完全重写关键句子
- 引入意外元素（出人意料的类比）
- 破坏 AI 模式（打破"问题-分析-解决"结构）
- 增加人类"缺陷"（轻微冗余、不精确但生动）

---

## 自适应策略系统

### 工作原理

```
┌─────────────────┐
│   输入文本      │
└────────┬────────┘
         ▼
┌─────────────────┐
│  第1轮处理      │
└────────┬────────┘
         ▼
┌─────────────────┐
│  检测分数分析    │
│  ZeroGPT: 0.45  │
│  GPTZero: 0.30  │
│  Copyleaks: 0.25│
└────────┬────────┘
         ▼
┌─────────────────┐
│ 识别最高分检测器 │
│ → ZeroGPT 最高  │
└────────┬────────┘
         ▼
┌─────────────────┐
│ 选择针对性策略   │
│ → 词汇多样化(3) │
└────────┬────────┘
         ▼
┌─────────────────┐
│  继续处理...    │
└─────────────────┘
```

### 策略映射

| 最高分检测器 | 推荐策略轮次 | 原因 |
|-------------|-------------|------|
| ZeroGPT | 3 → 4 → 6 | 对词汇多样性敏感 |
| GPTZero | 2 → 4 → 5 | 对突发性敏感 |
| Copyleaks | 1 → 2 → 6 | 对整体模式敏感 |

### 提前终止

当平均分数达到目标值（默认 0.1）时，自动停止处理，避免过度改写。

---

## 风格差异化处理

### 四种预设风格

#### 轻松随意 (casual)
```
语调：轻松、随意、亲切
词汇：口语化词汇、俚语、缩写
结构：短句为主、可用不完整句、允许口语化省略
个性：像朋友聊天、"我觉得"、"说实话"
```

**适用场景**：博客、社交媒体、日常交流

#### 学术正式 (academic)
```
语调：严谨、客观、专业
词汇：学术术语、精确用词、避免口语
结构：复杂句式、从句嵌套、逻辑严密
个性：引用式表达、谨慎的断言、承认局限性
```

**适用场景**：论文、学术报告、研究文档

#### 专业商务 (professional)
```
语调：专业、简洁、有说服力
词汇：行业术语、精炼用词、数据支撑
结构：清晰的论点、有力的论证、结论明确
个性：自信但不傲慢、解决问题导向、注重实效
```

**适用场景**：商业报告、提案、职业沟通

#### 创意写作 (creative)
```
语调：生动、形象、富有感染力
词汇：比喻、隐喻、感官词汇、创意表达
结构：节奏变化、意外转折、留白和暗示
个性：独特视角、情感表达、想象力丰富
```

**适用场景**：小说、散文、创意内容

---

## 技术实现细节

### 长文处理

| 参数 | 值 | 说明 |
|------|-----|------|
| CHUNK_THRESHOLD | 15,000 字符 | 触发分段的阈值 |
| MAX_CHUNK_SIZE | 20,000 字符 | 单段最大长度 |
| MAX_TOKENS | 30,000 | 模型输出上限 |

**分段策略**：
1. 优先按段落边界分割
2. 段落过长时按句子边界分割
3. 保持语义完整性

### 重试机制

```
重试次数: 5
基础延迟: 2000ms
策略: 指数退避 + 随机抖动

延迟计算: delay = base * 2^(attempt-1) + random(0, 1000)ms

重试场景:
- 超时 (timeout)
- 网络错误 (fetch failed, ECONNRESET)
- 限流 (429)
- 服务器错误 (500, 502, 503, 504)
```

### 超时配置

| 场景 | 超时时间 |
|------|---------|
| 普通文本 | 2 分钟 |
| 长文本 | 5 分钟 |

---

## 参考文献

### 学术论文

1. Mitchell, E. et al. (2023). "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature"
2. Kirchenbauer, J. et al. (2023). "A Watermark for Large Language Models"
3. Gehrmann, S. et al. (2019). "GLTR: Statistical Detection and Visualization of Generated Text"

### 行业报告

1. [Why Perplexity and Burstiness Fail to Detect AI](https://www.pangram.com/blog/why-perplexity-and-burstiness-fail-to-detect-ai) - Pangram Labs
2. [How Perplexity and Burstiness Make AI Text Undetectable](https://www.stealthgpt.ai/blog/how-do-perplexity-and-burstiness-make-ai-text-undetectable) - StealthGPT
3. [AI Text Detection Method Based on Perplexity Features](https://ceur-ws.org/Vol-3740/paper-261.pdf)
4. [Comparing AI Detectors: Evaluating Performance](https://ijsra.net/sites/default/files/IJSRA-2024-1276.pdf)

### 检测器官方文档

1. [GPTZero AI Detection Benchmarking](https://gptzero.me/news/ai-accuracy-benchmarking/)
2. [Copyleaks AI Content Detection](https://copyleaks.com/)
3. [ZeroGPT Detection System](https://www.zerogpt.com/)

---

## 更新日志

- **2024-12**: 初版策略设计
- **2025-01**: 增加自适应策略系统
- **2025-01**: 提升 Token 限制至 30,000
- **2025-01**: 优化长文分段处理

---

*本文档持续更新，欢迎贡献改进建议。*
